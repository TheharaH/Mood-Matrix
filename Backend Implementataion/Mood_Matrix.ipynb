{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGLtzWGbNqOn",
        "outputId": "05f045ab-c222-43a8-cf19-be1dd3f4f36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  Liked\n",
            "0                           Wow... Loved this place.      1\n",
            "1                                 Crust is not good.      0\n",
            "2          Not tasty and the texture was just nasty.      0\n",
            "3  Stopped by during the late May bank holiday of...      1\n",
            "4  The selection on the menu was great and so wer...      1\n",
            "Liked\n",
            "1    500\n",
            "0    500\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the TSV file\n",
        "df = pd.read_csv(\"/content/Restaurant_Reviews.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Save as a CSV file\n",
        "df.to_csv(\"sentiment_data.csv\", index=False)\n",
        "print(df.head())\n",
        "class_counts = df['Liked'].value_counts()\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize the Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Create a set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC8BDyJ_NxBx",
        "outputId": "dd31877e-0b78-4f26-f9ab-4a393a7ef3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "\n",
        "    text = re.sub(r'\\W', ' ', text)  # Replace characters except letters and digits with a space\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "\n",
        "    words = text.split()  # tokenization\n",
        "\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatize each word\n",
        "\n",
        "    return ' '.join(words)# Return the cleaned\n",
        "\n",
        "\n",
        "df['cleaned_review'] = df['Review'].apply(preprocess_text)\n",
        "print(df[['Review', 'cleaned_review']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTc38COWOCit",
        "outputId": "c2b9025d-0fe8-42dc-cb64-633621cab85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  \\\n",
            "0                           Wow... Loved this place.   \n",
            "1                                 Crust is not good.   \n",
            "2          Not tasty and the texture was just nasty.   \n",
            "3  Stopped by during the late May bank holiday of...   \n",
            "4  The selection on the menu was great and so wer...   \n",
            "\n",
            "                                      cleaned_review  \n",
            "0                                    wow loved place  \n",
            "1                                         crust good  \n",
            "2                                tasty texture nasty  \n",
            "3  stopped late may bank holiday rick steve recom...  \n",
            "4                         selection menu great price  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=600, ngram_range=(1, 2), min_df=5)\n",
        "X = vectorizer.fit_transform(df['cleaned_review']).toarray()\n",
        "y = df['Liked']\n"
      ],
      "metadata": {
        "id": "5ymIPWCaPTbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "lYL8p1mWV895"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Train Naive Bayes with regularization\n",
        "nb_model = MultinomialNB(alpha=2)\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, nb_model.predict(X_train))\n",
        "\n",
        "# Make predictions\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Testing Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSPGmL6UTZcA",
        "outputId": "8754767a-9a45-4c12-d246-5484bc7b1770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 81.86%\n",
            "Testing Accuracy: 74.00%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.71      0.73       152\n",
            "           1       0.72      0.77      0.75       148\n",
            "\n",
            "    accuracy                           0.74       300\n",
            "   macro avg       0.74      0.74      0.74       300\n",
            "weighted avg       0.74      0.74      0.74       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(nb_model, \"sentiment_model.pkl\")\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"sentiment_model.pkl\")\n",
        "files.download(\"tfidf_vectorizer.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L54vsKn8FpRA",
        "outputId": "20934cf3-8cb9-4924-ad9c-5999f01061a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8c848aa6-794d-4301-aacd-72fccbfd1a5a\", \"sentiment_model.pkl\", 9255)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c45200a-6a12-4964-b753-b1d685803ddf\", \"tfidf_vectorizer.pkl\", 10340)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}